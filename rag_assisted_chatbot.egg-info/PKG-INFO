Metadata-Version: 2.4
Name: rag-assisted-chatbot
Version: 2.0.0
Summary: RAG Assisted Chatbot Package
Home-page: https://github.com/Vijay-Takbhate-incred/simulator.git
Author: Vijay Dipak Takbhate
Author-email: vijay.takbhate@incred.com
License: MIT
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: OS Independent
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: certifi
Requires-Dist: chromadb
Requires-Dist: Markdown
Requires-Dist: langchain-community
Requires-Dist: langchain-core
Requires-Dist: langchain-openai
Requires-Dist: langchain-text-splitters
Requires-Dist: numpy
Requires-Dist: pydantic
Requires-Dist: PyMuPDF
Requires-Dist: python-dotenv
Requires-Dist: requests
Requires-Dist: scikit-learn
Requires-Dist: sentence-transformers
Requires-Dist: xhtml2pdf
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# RAG-Assisted Chatbot ‚Äî Portfolio & Interview Assistant üíºü§ñ

**RAG-Assisted Chatbot** is an installable Python package that powers a portfolio-driven HR interview assistant. It uses GitHub README scraping, PDF conversion, vectorization (ChromaDB), and Retrieval-Augmented Generation (RAG) combined with an LLM to answer HR-style questions based on a candidate's resume and repositories.

---

## üöÄ Highlights

- Scrapes GitHub repositories' README files and saves them as well-styled PDFs.
- Builds a persistent Chroma vector store from PDF content using SentenceTransformers embeddings.
- Queries the vector DB to fetch top-k relevant text chunks for a question (RAG).
- Uses an LLM (e.g., `gpt-5-mini` via `langchain-openai`) with structured output to produce interview-style responses.
- Packaged for easy reuse: import `Assistant`, `BuildVectorDB`, `AskToVectorDB`, and `GithubScrapper`.

---

## Table of contents

- [Quick overview](#-quick-overview)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Quickstart Examples](#-quickstart-examples)
- [How it works (architecture)](#-how-it-works-architecture)
- [Project structure](#-project-structure)
- [Troubleshooting & tips](#-troubleshooting--tips)
- [Contributing & License](#-contributing--license)

---

## üîç Quick overview

This project provides three main capabilities:

- GitHub scraping: `GithubScrapper` fetches README content and converts to PDF (uses `xhtml2pdf`).
- Vector DB builder: `BuildVectorDB` loads PDFs, splits text into chunks, encodes with `sentence-transformers`, and stores embeddings in ChromaDB.
- Assistant: `Assistant` pairs an LLM with the RAG results to answer HR-style questions using an up-to-date resume context.

---

## üß© Installation

Clone and install locally:

```bash
git clone <repo_url>
cd <repo>
python -m pip install -e .
```

Or install dependencies from `requirements.txt`:

```bash
python -m pip install -r requirements.txt
```

> Tip: Use a virtual environment (venv/conda).

---

## ‚öôÔ∏è Configuration

Project configuration values are in `rag_assisted_chatbot/config.py`:

- `GITHUB_USERNAME` ‚Äî username to scrape
- `GITHUB_PDF_FOLDER` ‚Äî folder to save generated PDFs
- `METADATA_JSON_PATH` ‚Äî metadata file location
- `VECTORDB_PATH` ‚Äî path for persistent ChromaDB storage
- `EMBEDDING_MODEL_NAME` ‚Äî embedding model (default `all-MiniLM-L6-v2`)
- `TOP_K_MATCHES` ‚Äî number of RAG results to include
- `GPT_MODEL_NAME` ‚Äî model used by the assistant (default `gpt-5-mini`)

Environment variables:

- `TOKEN_GITHUB` ‚Äî **required** GitHub personal access token for scraping private/read limits.

---

## ‚ú® Quickstart Examples

1) Scrape READMEs and save PDFs

```python
from rag_assisted_chatbot import GithubScrapper
import rag_assisted_chatbot.config as cfg

scraper = GithubScrapper(
    username=cfg.GITHUB_USERNAME,
    save_folder=cfg.GITHUB_PDF_FOLDER,
    metadata_save_folder=cfg.METADATA_JSON_PATH
)
scraper.scrap()
```

2) Build the persistent vector database

```python
from rag_assisted_chatbot import BuildVectorDB
import rag_assisted_chatbot.config as cfg

builder = BuildVectorDB(directory_path=cfg.GITHUB_PDF_FOLDER)
builder.build(chunk_size=300, chunk_overlap=100)
```

3) Run the assistant (interactive programmatic use)

```python
from rag_assisted_chatbot import Assistant
import rag_assisted_chatbot.config as cfg

assistant = Assistant(gpt_model_name=cfg.GPT_MODEL_NAME, temperature=0.7, rag_activated=True)
result = assistant.chat_with_model("Tell me about your key MLOps achievements")
print(result['question_category'])
print(result['response'].model_dump())
```

4) Query the Vector DB directly

```python
from rag_assisted_chatbot.ask_vectordb import AskToVectorDB
import chromadb
import rag_assisted_chatbot.config as cfg

client = chromadb.PersistentClient(path=cfg.VECTORDB_PATH)
collection = client.get_collection(name="my_embeddings")
asker = AskToVectorDB(collection=collection, embedding_model_name=cfg.EMBEDDING_MODEL_NAME)
res = asker.ask("Explain your role in the Medical Insurance project", n_results=3)
print(res['documents'][0])
```

---

## üèó How it works (architecture)

1. `GithubScrapper` fetches repository README files via GitHub API and saves them as PDFs.
2. `BuildVectorDB` loads PDFs with `PyMuPDF`, splits long texts into chunks using `RecursiveCharacterTextSplitter`, and encodes chunks with `SentenceTransformer`.
3. Embeddings are stored in a persistent ChromaDB collection (`my_embeddings`).
4. `AskToVectorDB` embeds queries and queries ChromaDB for top-k chunks.
5. `Assistant` obtains a category for the question, fetches RAG context (top-k chunks), and calls an LLM with a `SystemMessage` + retrieved context to provide a structured `InterViewResponse`.

Structured LLM output uses `pydantic` models from `rag_assisted_chatbot/output_structure.py` (fields include `response_message`, `reference_links`, `confidence_score`, `follow_up_question`).

---

## üìÅ Project structure

Key files and modules:

- `rag_assisted_chatbot/` ‚Äî package modules
  - `github_scrapper.py` ‚Äî GitHub README ‚Üí PDF
  - `build_vectordb.py` ‚Äî builds & persists ChromaDB embeddings
  - `ask_vectordb.py` ‚Äî queries vector DB
  - `main.py` ‚Äî `Assistant` class and CLI-style loop
  - `prompts.py`, `references.py` ‚Äî prompts and static resume content
  - `output_structure.py` ‚Äî pydantic models for structured outputs
  - `config.py` ‚Äî defaults you can edit
- `scrapped_data/`, `scrapped_metadata/` ‚Äî output folders used by scrapper
- `vectordb_storage/` ‚Äî persistent ChromaDB files

---

## üîß Troubleshooting & tips

- Missing GitHub token: `GithubScrapper` raises a runtime error if `TOKEN_GITHUB` is not set.
- If embeddings don't persist, ensure `VECTORDB_PATH` is writable and `chromadb` version is compatible.
- PDF loading requires `PyMuPDF` (package name `PyMuPDF`).
- Check `logs.log` in the project root for detailed runtime logs.

---

## ü§ù Contributing & License

Contributions welcome ‚Äî open an issue or PR with a clear description of the change. This project is licensed under **MIT**.

---

If you'd like, I can now:
- Add a short `CONTRIBUTING.md` and an example GitHub Actions workflow for CI ‚úÖ
- Add a `Makefile` / `scripts/` helpers to run common flows (scrape ‚Üí build ‚Üí query) ‚úÖ

If any of that sounds useful, tell me which you'd like next!
